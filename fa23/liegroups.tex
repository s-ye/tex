\documentclass[12pt]{article}
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{scribe}
\usepackage{listings}


\begin{document}

Songyu Ye 

sy459@cornell.edu

\today
\section{Universal enveloping algebra and PBW}
Consider the tensor algebra of a vector space $E$ \begin{align*}
    T(E) = \bigoplus_{i=0}^\infty E^{\otimes n} 
\end{align*}

\begin{definition}
The \textbf{symmetric algebra} of $E$ is the associative algebra $S(\mf g)$ defined as the quotient \begin{align*}
    S(E) = T(E) / J
\end{align*} 
\end{definition}
where $J = \langle x\otimes y - y\otimes x\rangle$. There are distinguished subspaces $S^n(E) = E^{\otimes n} / (E^{\otimes n} \cap J)$ which satisfies the following \textbf{universal property}. Every symmetric multilinear map to a vector space $E\times \dots \times E\to U$ factors uniquely through $E\times\dots \times E\to S(E)$.

\hfill

$S(E)$ satisfies the following universal property. Every linear map $E\to A$ where $A$ is \red{\textbf{commutative} associative algebra with identity} factors uniquely through $i:E\to S(E)$.

\begin{definition}
The \textbf{exterior algebra} of $E$ is the associative algebra $\Lambda(E)$ defined as the quotient \begin{align*}
    \Lambda(E) = T(E) / I
\end{align*} where $I$ is the two sided ideal generated by all symbols of the form $x\otimes x$ where $x\in E$. There are distinguished subspaces $\Lambda^n(E) = E^{\otimes n} / (I\cap E^{\otimes n})$ so that \begin{align*}
    \Lambda(E) = \bigoplus_{i=0}^\infty \Lambda^n(E)
\end{align*}
\end{definition} which satisfy the following universal property. Every alternating multilinear map to a vector space $E\times \dots \times E \to U$ factors uniquely through through $E\times\dots \times E\to \Lambda(E)$.

\hfill 

$\Lambda(E)$ satisfies the following universal property. Every linear map $\ell: E\to A$ with $\ell^2(v) = 0$ for all $v\in E$ where $A$ is \red{associative algebra with identity} factors uniquely through $i:E\to S(E)$.

\begin{definition}
The \textbf{universal enveloping algebra} of $\mf g$ is the associative algebra $U(\mf g)$ defined as the quotient \begin{align*}
    U(\mf g) = T(\mf g) / \langle x\otimes y - y\otimes x - [x,y]\rangle
\end{align*} Observe that when $\mf g$ is abelian we have that $U(\mf g)  = S(\mf g)$ the symmetric algebra. We have the distinguished subspace $U^n(\mf g) = \pi(\bigoplus_{i\leq n}g^{\otimes n})$ where $\pi:T(\mf g)\to U(\mf g)$ the quotient map. 
\end{definition}
\hfill 

$U(\mf g)$ has the universal property that every linear map $f:\mf g\to A$ with $f([x,y]) = f(x)f(y) - f(y)f(x)$ factors uniquely through $i:\mf g\to U(\mf g)$. Note that we have not yet shown that $i$ is injective. This follows from the following theorem.

\begin{theorem}
\textbf{(Poincare-Birkhoff-Witt):}
Let $x_1,\dots,x_n$ denote an ordered basis of $\mf g$. Then the monomials 
\begin{align*}
    x_1^{a_1}\dots x_n^{a_n}
\end{align*} for $a_i\in\Z_{\geq 0}$ form a basis for $U(\mf g)$. In particular the map $\mf g\to U(\mf g)$ is injective.
\end{theorem}
\begin{proof}

\begin{lemma}
Let $z_1,\dots,z_p \in \mf g$ adn let $\sigma$ a permutation of $[p]$. Then 
\begin{align*}
    i(Z_1)\dots i(Z_p) - i(Z_{\sigma(1)}) \dots i(Z_{\sigma(p)})
\end{align*} is in $U^{p-1}(\mf g)$. 
\end{lemma}
\begin{proof}[of the lemma]
WLOG assume $\sigma$ is a transposition. Then it follows from the relation \begin{align}
    i(Z_j)i(Z_{j+1}) - i(Z_{j+1})i(Z_j) = i[Z_j,Z_{j+1}] 
\end{align}
\end{proof}
Thus one sees that the $Y_I$ for all increasing tuples of length $\leq p$ generate $U^p(\mf g)$, where $Y_i= i(X_i)$.
Let $P$ be the poylnomial algebra $\C[z_1,\dots,z_n]$. Let $P_p$ be the monomials of degree.
We will construct an action of $\mf g$ on $P$ so that \begin{align}
    \pi(X_i)z_I = z_iz_I \text{ if $i\leq I$}
\end{align}
If we have such a representation, let us see that this implies the theorem. The 
identity implies that $Y_iz_I = z_iz_I$ if $i\leq I$ and as a consequence we can see that \begin{align*}
    (Y_{i_1}\dots Y_{i_k})1 = \dots z_{i_1}\dots z_{i_p}
\end{align*} and thus $\{Y_I \st I \text{ increasing}\}$ is linearly 
independent in $P$. We have already seen that it is spanning and so this proves the theorem.f
\end{proof}
\begin{example}
    Compute the PBW basis in the cases of $\mf u(2,\C),\mf{sl}_2(\C),\mf u(1,1)$. Compute the Casimir element as well.
\end{example}


\section{Semisimple Lie Algebras}
\begin{proposition}
    If $\mf g$ is a finite dimensional Lie algebra over $K$, then we have a symmetric invariant bilinear form $k:\mf g\times\mf g\to K$ given by \begin{align*}
        k(x,y) = \tr(\ad x \circ \ad y)
    \end{align*}
\end{proposition}
\red{Is the killing form necessarily nonzero? I guess there is Cartan's criterion which says that $k$ is nondegenerate if and only if $\mf g$ is semisimple, which means by definition that $\mf g$ has the radical (maximal solvable ideal) is $0$. This is (in the finite dimensional case) equivalent to the statemnet that $\mf g$ is a direct sum of simple lie algebras.}
\begin{proposition}
    If moreover we assume $\mf g$ is simple (i.e. has no nontrivial ideals), then $k$ is nondegenerate and unique up to scale.
\end{proposition}
\red{what I wrote above was alternatively written as:}
\begin{proposition}
Let $\mf g$ be a finite-dimensional simple Lie algebra over a field $K$. Then there exists, up to scalar, at most one invariant bilinear form on $\mf g$. If a nonzero invariant bilinear form exists it is nondegenerate and symmetric.
\end{proposition}
Why was it written like this? We know it exists right? It is just the Killing form, unless I am mistaken? We just have to worry about the nonzero-ness of the Killing form.
\begin{proposition}
Suppose that $\mf g$ has a \textbf{nondegenerate} invariant bilinear form $B$. Let $x_1,\dots,x_d$ be a basis of $\mf g$ and let $y_1,\dots,y_d$ be the dual basis with respect to the Killing form, i.e. $B(x_i,y_j) = \delta_{ij}$. Then $\Delta = \sum_{i}x_iy_i\in U(\mf g)$ is in the center of $U(\mf g)$.
\end{proposition}
\red{$\Delta$ is called the Casimir element for $\mf g$ with respect to $B$}
\red{example of when we have a bunch of invariant bilinear forms getting us a bunch of different Casimirs?}

\section{Reps of sl2}
\begin{example}
Consider the adjoint representation of $\so_3$ on $\so_4$. We have \begin{align*}
    \ad_{\so_3}(x\in\so_4) &= \begin{bmatrix}
        A & 0\\
        0 & 0 
    \end{bmatrix} \begin{bmatrix}
        B & w^T\\
        -w^T & 0 
    \end{bmatrix} -  \begin{bmatrix}
        B & w^T\\
        -w^T & 0 
    \end{bmatrix}\begin{bmatrix}
        A & 0\\
        0 & 0 
    \end{bmatrix} \\
    &= \begin{bmatrix}
        [A,B] & Aw^t \\
        wA^t & 0
    \end{bmatrix} = \so_3 \oplus \C^3
\end{align*}
In fact we claim that $\so_3\cong \C^3$, that is the adjoint representation of $\so_3$ is isomorphic to the standard representation. One can explicitly compute the intertwining element to see this isomorphism.
\end{example}

\begin{example}
Consider the adjoint representation of $\sl_2$ on $\sl_3$. We have \begin{align*}
    \sl_3 = \set{\begin{bmatrix}
        B & v\\
        w^T & -\tr B
    \end{bmatrix}} 
\end{align*} where $B\in\gl_2$.
\end{example}

\section{Borels and Complexification}
Consider $K = U(n)$ which is a maximal compact subgroup of $G = \GL_n\C$. Moreover $G$
is the complexification of $K$.

\begin{definition}
    Let $K$ Lie Group. A complexification of $K$ is a Lie group homomorphism $K\hookrightarrow G$
    where $G$ is a complex Lie group so that $\mf k$ is a real form of $\mf g$, i.e. $\mf k_\C\cong \mf g$.
\end{definition}

Not every real Lie group has a complexification. The standard example of this 
is the universal cover of $\SL_2$. This motivates the following definition: \begin{definition}
    Let $K$ be a connected Lie group. Then the universal complexification of $K$
    is a Lie group homomorphism $K\to G$ where $G$ is a complex Lie group so that
    any other Lie group homomorphism $K\to H$ where $H$ is a complex Lie group factors
    uniquely through $G\to H$, and moreover this map is analytic.
\end{definition}

\begin{theorem}
    Let $K$ be a connected Lie group. Then the universal complexification of $K$
    exists and is unique up to unique isomorphism.
\end{theorem}

\begin{theorem}
    $\sl(n,\R)$ has complexification $\sl(n,\C)$.
\end{theorem}

\begin{proof}
    Consider $f:\sl(n,\R)\to H$ where $H$ is complex analytic. The differential gives us a map 
    $df:\mf{sl}_n\R\to \mf h$ where $\mf h$ is a complex Lie algebra. By the property of 
    complexification of Lie algebras, we get an induced map $\mf{sl}_n\C\to \mf h$. 
    Since $\mf{sl}(n,\C)$ is simply connected this map is the differential of a unique map $\sl(n,C)\to H$.
    \red{there are two things that I need to check here}

    Finally we need to see that $f$ is analytic. This is true because of the following diagram:
\[\begin{tikzcd}
	\sl(n\C & Lie(H) \\
	\sl(n\C & H
	\arrow[from=1-1, to=1-2]
	\arrow[from=1-2, to=2-2]
	\arrow[from=2-1, to=2-2]
	\arrow[from=1-1, to=2-1]
\end{tikzcd}\] We know that every map in the diagram is holomorphic except for perhaps the bottom one. Then we are done
since $\exp$ is a local homeo and near $g\in G$ we can translate $F = L(f(g))\circ F\circ L(g^{-1})$.\end{proof}

\begin{theorem}
    Let $K$ be a compact connected Lie group. Then $K$ has a complexification $K\to G$. This map induces 
    an isomorphism on $\pi_1$. Moreover $\Lie(G) = \Lie(K)\otimes_\R\C$. Any faithful complex 
    representation of $K$ extends to a complex analytic representation of $G$. Any analytic rep of $G$ is completely reducible.
\end{theorem}

\begin{theorem}
    Let $K$ compact connected. Then the universal complexification of $K$ coincides with 
    the complexification of $K$. In particular compact groups have complexifications.
\end{theorem}


In this following discussion we will be considering the following subgroups.
Consider maximal torus $T\subset K$ consising of diagonal matrices with $\abs{\lambda_i} = 1$. 
We have the complex torus $T_\C$ which factors $T_\C = TA$ where $A$ is those
diagonal matrices with $\lambda_i\in\R_{>0}$. We also have \begin{align*}
    G \supset B \supset B_0 \supset N
\end{align*} where $B$ is upper triangular matrices, $B_0$ is upper triangular matrices 
with $\R^+$ on the diagonal (i.e. the connected component of $B$ containing $I$),
 and $N$ is the upper triangular matrices with $1$ on the diagonal.

\begin{proposition}
    (Iwasawa decomposition)
    Every $g\in G$ factors uniquely $g = avk$ where $a\in A$, $v\in N$, $k\in K$. Moreover the map 
    $A\times N\times K\to G$ is a diffeomorphism.
\end{proposition}

\begin{proof}
    Let $v_1,\dots,v_n$ rows of $g$. Gram Schmidt says there exists $t_{ij}$ for $i<j$ so that \begin{align*}
        v_n,v_n+t_{n-1,n-1}v_{n-1},\dots,v_n + t_{1,n-1}v_{n-1} + \dots + t_{1,1}v_1
    \end{align*} are orthogonal. Let $u_i$ be those vectors.
    Put \begin{align*}
        v^{-1} &= \begin{bmatrix}
            1 & t_{1,1} & \dots & t_{1,n-1}\\
            & 1 & \dots & t_{2,n-1}\\
            & & \ddots & \vdots\\
            & & & 1
        \end{bmatrix}\\
        a &= \begin{bmatrix}
            \abs{u_1} & & 0\\
            & \ddots & \\
            0 & & \abs{u_n}
        \end{bmatrix}
    \end{align*}
    Then $k = a^{-1}v^{-1}g$ has orthonormal rows and hence is unitary. This shows onto. 
    Injectiivty follows from the fact that $B_0\cap K = 1$ and $A\cap N = 1$.
\end{proof}

The following lemma will help us prove Lie's theorem.
\begin{lemma}
    (Dynkin) Let $V$ finite dimeisonal over $F$ characteristic $0$. Let $\mf g\subset \gl(V)$ and $\mf h\leq \mf g$ ideal.
    Let $\lambda:\mf h\to F$ linear form. Then \begin{align*}
        W = \set{v\in V: hv = \lambda(h)v\text{ for all }h\in\mf h}
    \end{align*} is $\mf g-$invariant.
\end{lemma}
\begin{proof}
    Let $v\in W$ nonzero and $X\in\mf g$. We want to show $Xv\in W$.
    
    Consider $W_0 = \ideal{v_0,Xv_0,\dots, X^{d-1}v_0}$. Let $Z\in\mf h$. Then $Z(W_0)\subset W_0$ we have the following trace formula \begin{align*}
        \tr Z\vert_{W_0} = \dim(W_0)\lambda(Z)
    \end{align*} This follows from the fact that the matrix for $Z$ with respect to the given basis for $W_0$ is upper triangular. One can see this by induction.
    \begin{align*}
        ZX^iv = XZX^{i-1}v + [Z,X]X^{i-1}v = \lambda(Z)X^iv + \sum_{j<i}c_jX^jv +\lambda([Z,X])X^{i-1}v
    \end{align*} by induction. Then the trace formula clearly follows. Then we have \begin{align*}
        ZXv = XZv + [Z,X]v = \lambda(Z)Xv + \lambda([Z,X])v  = \lambda(Z)Xv
    \end{align*} since $[Z,X]\in\mf h$, so $0 = \dim(W_0)\lambda([X,Z])$ and we are over characteristic zero.
\end{proof}

\begin{theorem}
    (Lie) Let $\mf b\subset \mf{gl}(V)$ solvable where $V$ finite dimensional over $F$ characteristic $0$. \begin{enumerate}
        \item There exists a simultaneous eigenvector for all of $\mf b$.
        \item There exists a basis for $V$ so that $\mf b$ is upper triangular.
    \end{enumerate}
\end{theorem}
\begin{proof}
    Since $\mf b$ is solvable, $[\mf b,\mf b]$ is proper and hence $\mf b$ has a codimension $1$ ideal $\mf h$.
    Let $\lambda$ the corresponding weight and let $W = \set{v\in V: hv = \lambda(h)v\text{ for all }h\in\mf h}$.
    Then $W$ is nonempty and hence $\mf b-$invariant by the lemma. Let $Z\in \mf b\backslash\mf h$.
    Then $Z$ has an eigenvector $v_1$ on $W$ since $F$ is algebraically closed. $v_1$ is an eigenvector for all of $\mf b$ since it already is for $\mf h$.
    Claim (ii) follows from induction on $V/Fv_1$.
\end{proof}

Now let $K$ be a compact connected Lie group, $G$ its complexification. Let $\mf k = \Lie(K)$ and $\mf g = \Lie(G)$. $K$ has a maximal torus $T$,
its complexification $T_\C$ embeds in $G$ by the universal property.

Let $\Phi$ root system of $K$ and pick system of positive roots $\Phi^+$. We will see that this amounts to picking a Borel subgroup. 
We can put \begin{align*}
    \mf n = \bigoplus_{\alpha\in\Phi^+}\mf g_\alpha
\end{align*} where $\mf g_\alpha$ is the $1$-dimensional root space corresponding to $\alpha$. Then $\mf n$ is nilpotent and hence solvable.

\begin{definition}
    A Lie algebra $\mf n$ is nilpotent if its lower central series defined by \begin{align*}
        \mf n_1 = \mf n,\quad \mf n_{k+1} = [\mf n_k,\mf n]
    \end{align*} eventually terminates. This is equivalent to asking for the existence of a chain of ideals \begin{align*}
        \mf n = \mf n_1\supset \mf n_2\supset \dots \supset \mf n_k = 0
    \end{align*} where $\mf n_i \supset [\mf n_{i-1},\mf n]$.
\end{definition} 

\begin{proposition}
    $\mf n$ is nilpotent.
\end{proposition}
\begin{proof}
    Let $\Phi^+_k$ denote the set of positive roots expressible as the sum of at least $k$ positive roots.
    Then $\mf n_k = \bigoplus_{\alpha\in\Phi^+_k}\mf g_\alpha$ is nilpotent by induction on $k$.
\end{proof}
Let $\mf t = \Lie(T)$ and $\mf b = \mf t\oplus \mf n$. Then $\mf b$ is a complex Lie algebra. 
Moreover $[\mf b,\mf b]\subset \mf n$ so $\mf b$ is solvable.

\begin{theorem}
    Put $N = \exp(\mf n)$ and $B = \exp(\mf b)$. Then \begin{enumerate}
        \item $B$ and $N$ are closed subgroups of $G$, and $Lie(B) = \mf b$ and $Lie(N) = \mf n$.  
        \item We can embed $G\hookrightarrow\GL_n\C$ so that $B$ is the subgroup of upper triangular matrices,
        $K$ is the subgroup of unitary matrices, and $T_\C$ is the subgroup of diagonal matrices.
        \item If $\mf v,\mf w$ are complex Lie subalgebras of $\mf n$ so that $\mf n = \mf v\oplus \mf w$ then $V = \exp \mf v$ is a closed Lie subgroup of $G$
        and $N = V\cdot W$ and $V\cap W = 1$.
    \end{enumerate}
\end{theorem}
From this theorem, one obtains the Iwasawa decomposition for all $K\to G$ complexification of compact connected Lie group.

\section{Compact Lie groups}
\begin{theorem}
    (Cartan/Polar decomposition) The multiplication map $P\times U(n)\to \GL_n$ is a diffeomorphism, where $P$
    is the space of positive definite Hermitian matrices.
\end{theorem} This result follows from discussions about the universal covers of these groups. 
\begin{theorem}
    \begin{enumerate}
        \item (Lie's homomorphism theorem) If $G$ is simply connected then every $\mf g\to \mf h$ extends uniquely to $G\to H$.
        \item There exists a simply connected Lie group $G$ with Lie algebra $\mf g$ for all Lie algebras $\mf g$. 
        \item Every rep of $G$ actually comes from a rep of $\tilde G$ where $\tilde G$ is the universal cover.
    \end{enumerate}
\end{theorem}
Say that you want to study the classification of compact Lie groups. One can do this as follows.
\begin{fact}
    If $G$ and $H$ are compact and simply connected and they have the same Lie algebra, then $G\cong H$.
\end{fact}
\begin{fact}
    If $G$ is any Lie group then its universal cover $\tilde G$ is naturally a Lie group for which 
    $G = \tilde G/Z$ where $Z\subset Z(\tilde G)$.
\end{fact}
These two facts imply that to classify compact Lie groups, it suffices to classify
compact simply connected Lie groups, and then compute the centers. These in turn are in 
correspondence with complex semisimple Lie algebras. If I have a compact simply conneced Lie group, I can take
the complexification of its Lie algebra. Conversely, every complex semisimple Lie algebra has a unique compact real form which
is isomorphic to the Lie algebra of a unique compact simply connected Lie group.

\section{Meeting Nov 17}
We thought about a theorem which will help us decompose representations of the complexification of a connected compact group.

Birgit recommended that I do more reading about compact groups, in particular think about Chapter 23 of Bump.

She also encouraged that I fill the holes in my knowledge. In particular she remarked that th
ere are two sort of big pieces of machinery
that I was sweeping under the rug.

The Lie Algebra of a compact group is semisimple.
We have this sort of equivalence of categories between compact groups and complex analytic groups, one way is complexification and the other way
is to look at a maximal compact subgroup of our complex analytic group, \red{this should be unique up to something...?}

Let $G$ be the complexification of a compact connected Lie group $K$. Let $T$ be a maximal torus of $K$ and $T_\C$ its complexification.
$\mf g$ acts on itself via the adjoint representation, and we can apply the Cartan decomposition to this representation \begin{align*}
    \mf g = \bigoplus_{\lambda\in\mf h^*}g_\lambda
\end{align*} where $\mf g_\lambda = \set{v\in \mf g\st [X,v] = \lambda(X)v}$.

With some work one can show that these weight spaces are in fact one dimensional.

Pick a set of positive roots $\Phi^+$. Now we consider the Lie Algebra defined by \begin{align*}
    \mf n &= \bigoplus_{\lambda\in\Phi^+} g_\lambda \\
    \mf n_- &= \bigoplus_{\lambda\in\Phi^-} g_\lambda
\end{align*} and we can consider the set $N = \exp\mf n$. $N$ will turn out be a closed Lie
subgroup of $G$. Now we have the following theorem.
\begin{theorem}
Let $\pi,V$ be a finite dimensional irreducible complex $K$-module and extend
it to an analytic finite dimensional $G$ module. Let $\lambda$ highest weight.
Then $V(\lambda) = V^N$.
\end{theorem}
\begin{proof}
    We will need to invoke the following lemma.
\end{proof}

\begin{lemma}
    The map $U(n_-)\otimes U(\mf t)\otimes U(\mf n) \cong U(\mf g)$.
\end{lemma}
\begin{proof}
    This comes from PBW plus a little extra work. This map is certainly surjective, 
    one can look at the standard basis monomials.
\end{proof}

\section{The irreps of SL2}

Let $F = \R,\C$. I have an obvious action of $\sl(2,F)$ on the vector space $F^2$. If we endow $F^2$ with coordinates $X,Y$
we can consider the vector space of homogeneous polynomials of degree $n$ in $X,Y$. This is an $n+1$ dimensional
vector space with basis $X^n,X^{n-1}Y,\dots,Y^n$. 
We can consider the action of $sl(2,F)$ on this vector space \begin{align*}
    g\cdot P(X,Y) = P(\inv{g}\cdot (X,Y))
\end{align*} These are all of the finite dimensional complex irreps of $\sl(2,F)$. This classification is done
by considering the classification of finite dimensional irreps of $\mf{sl}_2F$. Recall that we get an induced representation
by \begin{align*}
    X\cdot P(X,Y) &= \frac{d}{dt}(\exp(tX)\cdot P(X,Y))\vert_{t=0}\\
\end{align*}

Consider the Casimir element with respect to the Killing form for the adjoint representation. In particular 
we have the following theorem: 
\begin{theorem}
    Suppose $\mf g$ has $B$ nondegenerate invariant bilinear form. Let $\set{x_i}$ be an ordered basis for $\mf g$
    and $\set{y_i}$ the dual basis with respect to $B$.
    Then $\Delta = \sum_{i=1}^n x_iy_i$ is in the center of $U(\mf g)$ and 
    does not depend on the choice of basis.
\end{theorem}

\begin{proposition}
    Let $V$ irrep of $\mf g$ Lie Algebra. Then any $z\in Z(U(\mf g))$ acts on $V$ as a scalar.
\end{proposition}
\begin{proof}
    Let $\lambda$ any eigenvector of $z$ and $U$ be the $\lambda$-eigenspace for $z$. $z$ commutes with $x$ 
    so $xU\subset U$ for all $x$. Then $U$ is a $\mf g-$submodule of $V$. Since $V$ is irreducible, $U = V$.
\end{proof} 

Dual to the basis $H,R,L$ is $H,2R,2L$ and so we compute the Casimir element for $\sl(2,F)$ as \begin{align*}
    \Delta = H^2 + 2RL + 2LH
\end{align*}
Here is a key property of the Casimir element.
\begin{lemma}
    Let $V$ be an irrep of $\sl(2,F)$ with highest weight $\lambda$. Then $\Delta$ acts on $V$ as $\lambda^2 + \lambda$.
\end{lemma}
\begin{proof}
    The proposition tells us that $\Delta$ acts by a scalar $k$. We compute $k$ by looking at the action of $\Delta$ on the highest weight vector.
    \begin{align*}
        \Delta v &= (H^2 + 2RL + 2LH)v \\
        &= (H^2 + 2H + 4LR)v \\
        &= (\lambda^2 + 2\lambda)v
    \end{align*}
\end{proof}
This observation is important because the Casimir element gives us a purely algebraic way of seeing
that representations of complex semisimple Lie algebras are reducible (Weyl's theorem can be shown nonalgebraically as well).
The key ideas are that \begin{enumerate}
    \item $[\mf g,\mf g] = \mf g$
    \item For $V$ irreducible $\Delta$ acts by a scalar $\lambda$ which is zero if and only if $V$ is irreducible
\end{enumerate}

Note that we verified these facts in the case that $\mf g = \sl(2,F)$.

\begin{proposition}
    Let $\mf g = \sl_2\F$ or $\su(2)$ and let $V$ finite dimensional complex representation of $\mf g$.
    If there exists $\Delta^k \cdot v = 0$ for all $v\in V$ then $x\cdot v = 0$ for all $x\in\mf g$.
\end{proposition}
\begin{proof}
    Suppose $V\neq 0$ and consider $U$ maximal $\mf g$-submodule of $V$. Then $V/U$ is irreducible 
    and by our classification we know that \red{not finished}
\end{proof}

\begin{proposition}
    Let $\mf g = \sl_2\F$ or $\su(2)$ and let $V$ finite dimensional complex representation of $\mf g$.
    \begin{enumerate}
        \item If $v\in V$ and $\Delta^2v = 0$ then $\Delta v = 0$.
        \item $V$ decomposes as $\ker\Delta\oplus \im\Delta$. Both are invariant subspaces. Moreover $\mf g\cdot \ker\Delta = 0$.
        \item The set $V_0 = \set{v\in V\st X\cdot v = 0}$ is a $\mf g-$submodule of $V$.
        \item The invariants functor is a functor and it is exact.
    \end{enumerate}
\end{proposition}

\begin{exercise}

    Show that each representation of $\sl(2,\R)$ comes from a representation of $\SL(2,\R)$.
\end{exercise}

\begin{exercise}
    Let $g = \mathfrak{sl}(3, \mathbb{R})$. 
    Let $\Delta$ be the Casimir element with respect to the invariant bilinear form $\operatorname{tr}(xy)$ on $g$. 
    Show that if $(\pi, V)$ is an irreducible representation with $\Delta \cdot V = 0$, then $V$ is trivial.
\end{exercise}


\section{Theorems of the highest weight}
\red{I tried writing up the theorem of the highest weight. Akhil Mathews has some good notes for this}
Let $\mf g$ be a Lie algebra. Let $V$ be a finite dimensional irrep of $\mf g$. 
Consider a Cartan subalgebra $\mf h\subset \mf g$. This means we are asking for
a maximal abelian subalgebra of $\mf g$. We can produce Cartan subalgebras for $\mf g$
whenever $\mf g$ is a finite dimensional Lie algebra over an infinite field. If we have a Cartan subalgebra $\mf h$ then we have a decomposition of $V$ into weight spaces \begin{align*}
    V = \bigoplus_{\lambda\in\mf h^*}V_\lambda
\end{align*} where $V_\lambda = \set{v\in V\st hv = \lambda(h)v\text{ for all }h\in\mf h}$.
This is because commuting diagonizable matrices are simultaneously diagonizable. If $A$ and $B$ commute 
and are diagonalizable, then we see that $BAx = ABx = \lambda Ax$
and so $A$ preserves the eigenspaces of $B$. Being diagonalizable $B$ has 1-dimensional eigenspaces and
so $A$ actually sends a basis element of the $B$ eigenspace to a scalar multiple of itself. 
This means that any eigenbasis of $B$ is also an eigenbasis of $A$ and so $A$ and $B$ are simultaneously diagonalizable.



Now if we let $V = \mf g$ is the adjoint representation, then we have a decomposition \begin{align*}
    \mf g = \bigoplus_{\lambda\in\mf h^*}\mf g_\lambda
\end{align*} and we will call the $\lambda$ which appear the roots of $\mf g$.

We have the following important observation that
 $\mf g_\alpha \cdot V_\lambda\subset V_{\lambda + \alpha}$.
This is because \begin{align*}
    HX_\alpha\cdot v_\lambda = X_\alpha H\cdot v_\lambda + [H,X_\alpha]v_\lambda = (\alpha+\lambda)(H)X_\alpha v
\end{align*} In particular this tells us that all of the weights that appear in a decomposition
of a finite dimensional irrep are related by translates of the root vectors. Thus it makes sense to consider 
the root lattice $\Phi$ which is the free lattice generated by the roots. 




Thinking about the classification of representations of $\mf{sl}_2\F$ we saw that each irreducible
representation had an eigenvalue which was most extreme, and that this eigenvalue determined
the representation. In general, we need to make a choice of extremity, and this is what the notion
of positive roots is about.

\hfill

We can get ahold of a system of positive roots informally by slicing the root lattice with a hyperplane.
In particular we are asking for $\Phi^+\subset \Phi$
so that $\Phi^+\cap -\Phi^+ = \emptyset$ and $\Phi^+\cup -\Phi^+ = \Phi$. Then we can define highest 
weight vectors of $V$ to be vectors so that $X\cdot v = 0$ for all $X\in\mf g_\alpha$ where $\alpha\in\Phi^+$.

\hfill

Being finite dimensional $V$ will necessarily have a highest weight vector. The key idea is that
the weights are translates of the root vectors and 
 We can then show the following

\hfill

$V$ is a finite dimensional irrep if and only if it has a 1-dimensional highest weight space.
Its translates are all of the other weight spaces and hence all of the other weight spaces are also 1-dimensional.



Moreover, if $V$ is a finite dimensional irrep with highest weight $\lambda$ then $\lambda$ is dominant, i.e. $\lambda(h)\geq 0$ for all $h\in\mf h$
and integral, i.e. $\lambda(h)\in\Z$ for all $h\in\mf h$. Moreover, if $\lambda$ is dominant and integral then there exists 
a unique finite dimensional irrep of $\mf g$ with highest weight $\lambda$.

\red{Why does this theory only work for semisimple Lie algebras? Is it true that 
a Lie algebra is semisimple if and only if every representation is completely reducible?}


\section{Lie algebra cohomology}
\subsection{De Rham cohomology / Motivation}
Lie algebra cohomology is motivated by the chain complex of differential forms on a manifold.
First we recall De Rham cohomology. Let $M$ be a smooth manifold. Then we have the following chain complex \begin{align*}
    \Omega^0(M) \xrightarrow{d} \Omega^1(M) \xrightarrow{d} \Omega^2(M) \xrightarrow{d} \dots
\end{align*} where $\Omega^k(M)$ is the space of smooth $k$-forms on $M$ and $d$ is the exterior derivative, given by \begin{align*}
    d(f dx_1\wedge\dots\wedge dx_k) = df\wedge dx_1\wedge\dots\wedge dx_k
\end{align*} where $df = \sum \frac{\partial f}{\partial x_i}dx_i$. One can check that we have \begin{align*}
    d^2 &= 0 \\
    d(\omega\wedge\eta) &= d\omega\wedge\eta + (-1)^|\omega| \omega\wedge d\eta
\end{align*}

We can then define the $k$th De Rham cohomology group as \begin{align*}
    H^k_{DR}(M) = \frac{\ker d:\Omega^k(M)\to \Omega^{k+1}(M)}{\im d:\Omega^{k-1}(M)\to \Omega^k(M)}
\end{align*} 

We want to get ahold of more general cohomology theories. Recall that the Lie algebra can be identified
with the space of left invariant vector fields on $G$. If we think of $\mf g$ as the space of velocity vectors
of smooth curves passing through the identity, then for each $c\in\mf g$ we can define a left invariant vector field
by \begin{align*}
    X_c(f) = \frac{d}{dt}f(\exp(tc))\vert_{t=0}
\end{align*} and this gives us an isomorphism of vector spaces $\mf g\cong \set{\text{left invariant vector fields on }G}$.

\hfill

Fix a basis $\set{X_i}$ of left invariant vector fields, and let $\set{\omega^i}$ be the dual basis of left invariant $1$-forms.
Then $n$-forms on $G$ look like \begin{align*}
    \sum_{i_1,\dots,i_n}f_{i_1,\dots,i_n}\omega^{i_1}\wedge\dots\wedge\omega^{i_n}
\end{align*} and we want to compute the exterior derivative of this expression. One observes that for $f\in C^\infty(G)$ we have \begin{align*}
    df = \sum (X_if)\omega^i
\end{align*} and using the formula for the exterior derivative of a wedge product one works out \begin{align*}
    d(f \omega^{i_1}\wedge\dots\wedge\omega^{i_n}) = \sum_{j=1}^n (-1)^{j-1}X_{i_j}f\omega^{i_j}\wedge \omega^{i_1}\wedge\dots\wedge\hat\omega^{i_j}\wedge\dots\wedge\omega^{i_n}
\end{align*} We can simplify by identifying the space of $n$ forms with the space of alternating $n$-multilinear functions on $\mf g$.
Recall that this identification is made by looking at
\begin{align*}
    \omega^{i_1} \wedge \dots \wedge \omega^{i_n}(Y_{j_1},\dots,Y_{j_n}) = \det{\omega^{i_j}(Y_{j_k})}\vert_{s,t=1}^n
\end{align*}
and so we can write 
\begin{align}
    d\omega(Y_1,\dots,Y_{n+1}) &= \sum_{j=1}^{n+1}(-1)^{j-1}Y_j\omega(Y_1,\dots,\hat Y_j,\dots,Y_{n+1}) \notag\\
    & + \sum_{i<j}(-1)^{i+j}\omega([Y_i,Y_j],Y_1,\dots,\hat Y_i,\dots,\hat Y_j,\dots,Y_{n+1})\label{eq:exterior derivative}
\end{align}
This is the formula we will use for general Lie algebra cohomology. See \cite{Knapp} for more details.

\subsection{Lie algebra cohomology}
Let $V$ be a representation of $\mf g$. We can define the cochains \begin{align*}
    C^n(\mf g,V) = \Hom(\Lambda^n\mf g,V)
\end{align*} and the exterior derivative $d$ is defined by the same formula as in \eqref{eq:exterior derivative}.
Notice that De Rham cohomology is a special case of this construction, where we take $V = C^\infty(G)$ and $\mf g$ acts on $V$ by left invariant vector fields.

We have a special tool which aids us in computing Lie algebra cohomology called the Koszul complex.
Let $X_n = U(\mf g) \otimes_\C \Lambda^n\mf g$ and let $d_n:X_n\to X_{n-1}$ be defined by \begin{align*}
    d_{n-1}(u \otimes x_1 \wedge \dots \wedge x_n) &= \sum_{j=1}^n (-1)^{j-1}(uX_1 \wedge \dots \wedge \hat X_j \wedge \dots \wedge X_n) \\
    & +\sum_{l<k}(-1)^{l+k}u\otimes [X_l,X_k] \wedge X_1 \wedge \dots \wedge \hat X_l \wedge \dots \wedge \hat X_k \wedge \dots \wedge X_n
\end{align*} We regard $X_n$ as a $U(\mf g)$ module by letting $U(\mf g)$ act on the first factor and acting trivially on the second factor. We have the following complex \begin{align*}
    \xrightarrow{d_n} X_n \xrightarrow{d_{n-1}} X_{n-1} \xrightarrow{d_{n-2}} \dots \xrightarrow{d_1} X_0 \xrightarrow{\varepsilon} \C \to 0
\end{align*} where $\varepsilon:U(\mf g)\to \C$ extracts the constant term. This is
called the Koszul complex. We can then define the Lie algebra cohomology groups as cohomology of this complex.

The Koszul resolution is a projective resolution for the trivial module $\C$. Fix $V$ a $\mf g$ module. 
We consider the functors \begin{align*}
    X \mapsto \Hom_{\C}(X,V) \quad\text{and}\quad X\mapsto X\otimes_{U(\mf g)}V
    X \mapsto X\otimes_\C V
\end{align*} Applying these functors to the Koszul resolution, one can show that we obtain injective and projective resolutions
\begin{align*}
    0 \leftarrow V \leftarrow \Hom_{\C}(X_0,V) \leftarrow \Hom_{\C}(X_1,V) \leftarrow \dots \\
    0 \to V \to X_0\otimes_\C V \to X_1\otimes_\C V \to \dots
\end{align*} These are the standard projective and injective resolutions for $V$. We also have the 
following functors:\begin{align*}
    V\mapsto V^{\mf g} \\
    V \mapsto V/\mf g V
\end{align*}

The point is that Lie algebra homology and cohomology (which is defined as the derived functors of the coinvariants/invaraints functors) can be computed
using these resolutions. In particular, the category of $\mf g$-modules has enough injectives and projectives.
\section{Relative Lie algebra cohomology}
Cohomology helps us construct representations of reductive groups, which for us will be 
closed linear subgroups of $\GL_n\C$ closed under conjugate transpose. 

\hfill

Let $\mf g$ be a finite dimensional complex Lie algebra and $K$ compact Lie group, compatible in the following sense
\begin{enumerate}
    \item $\mf k = \Lie(K)_\C $ is a subalgebra of $\mf g$.
    \item $K$ acts on $\mf g$ by automorphisms.
    \item The differential of $\Ad K$ is $\ad \mf k$
\end{enumerate}

A $(\mf g,K)$ module (Harish-Chandra module) is a complex vector space with $\mf g$ action and $K$ action compatible in the following sense 
\begin{enumerate}
    \item The $K$ representation splits as the possibly infinite direct sum of finite dimensional irreducible representations
    \item the differentiated version of the $K$ action is the restriction of $\mf k$ to the $\mf g$ action
    \item $(\Ad(k)u)x = k(u(k^{-1}x))$ for $k\in K$, $u\in U(\mf g)$ and $x\in V$.
\end{enumerate}

How does one produce $(\mf g,K)$ modules? 
We care about the $K$-finite vectors, i.e. those vectors whose $K$ translates span a finite dimensional space.
In particular, we can consider the $K$-finite functor, whick takes $V$ module over $\mf g$ and consider its derived functors.
Then as it turns out for a given $V$ there exists exactly one $n$ so that $R^nK_\text{fin}(V) \neq 0$, and 
this cohomology group will turn out to be a $(\mf g,K)$ module.
\begin{thebibliography}{9}
    \bibitem{Bump}
    Daniel Bump, \textit{Lie Groups}, Springer, 2013.
    \bibitem{Knapp}
    Anthony Knapp, \textit{Lie Groups, Lie Algebras, and Cohomology}, Princeton University Press, 2016.
\end{thebibliography}
\end{document}